{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b7e81c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available:  True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, matthews_corrcoef\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import random\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import transformers\n",
    "from tqdm import tqdm, trange\n",
    "import io\n",
    "from utils import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "########################### Check if cuda available ############################\n",
    "print(\"Cuda available: \", torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1adae5c",
   "metadata": {},
   "source": [
    "### Discover causal tweet dataset\n",
    "\n",
    "Read some random tweets to get an idea about the labeling\n",
    "\n",
    "*You will certainly find some mislabelings. Labeling causal relationships is challenging*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d6345",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"data/causal_tweets_labeled.parquet\"\n",
    "\n",
    "data = pd.read_parquet(dataPath)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e9bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d25d860a",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd8d354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20065, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Causal association</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tonight , I learned my older girl will back he...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[tonight, ,, I, learned, my, older, girl, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fiercely .</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Fiercely, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#impressive #bigsister #type1 #type1times2</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[#impressive, #bigsister, #type1, #type1times2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER USER I knew diabetes and fibromyalgia wer...</td>\n",
       "      <td>joke</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[USER, USER, I, knew, diabetes, and, fibromyal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>:face_with_rolling_eyes:</td>\n",
       "      <td>joke</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[:face_with_rolling_eyes:]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence Intent Cause Effect  \\\n",
       "0  tonight , I learned my older girl will back he...         None   None   \n",
       "1                                         Fiercely .         None   None   \n",
       "2         #impressive #bigsister #type1 #type1times2         None   None   \n",
       "3  USER USER I knew diabetes and fibromyalgia wer...   joke  None   None   \n",
       "4                           :face_with_rolling_eyes:   joke  None   None   \n",
       "\n",
       "   Causal association                                          tokenized  \n",
       "0                 0.0  [tonight, ,, I, learned, my, older, girl, will...  \n",
       "1                 0.0                                      [Fiercely, .]  \n",
       "2                 0.0    [#impressive, #bigsister, #type1, #type1times2]  \n",
       "3                 0.0  [USER, USER, I, knew, diabetes, and, fibromyal...  \n",
       "4                 0.0                         [:face_with_rolling_eyes:]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################### LOAD TWEETS (already split in sentences) ###########################\n",
    "\n",
    "# The dataset above is the original one, which was labeled on a tweet level.\n",
    "# This dataset contains the same tweets, but already split into sentences\n",
    "# We simplified the problem by only studying causal relationships in a single sentence\n",
    "\n",
    "dataPath = \"../input/data/causal_sentences_labeled.parquet\"\n",
    "\n",
    "data = pd.read_parquet(dataPath)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a01902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of sentences before filtering:  20065\n",
      "Count of sentences after filtering:  16475\n",
      "Distribution:\n",
      "0.0    14364\n",
      "1.0     2111\n",
      "Name: Causal association, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Causal association</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tonight , I learned my older girl will back he...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[tonight, ,, I, learned, my, older, girl, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#impressive #bigsister #type1 #type1times2</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[#impressive, #bigsister, #type1, #type1times2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>:down_arrow: :down_arrow: :down_arrow: THIS :d...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[:down_arrow:, :down_arrow:, :down_arrow:, THI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I 'm a trans woman .</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[I, 'm, a, trans, woman, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Both of us could use a world where \" brave and...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Both, of, us, could, use, a, world, where, \",...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence Intent Cause Effect  \\\n",
       "0  tonight , I learned my older girl will back he...         None   None   \n",
       "2         #impressive #bigsister #type1 #type1times2         None   None   \n",
       "5  :down_arrow: :down_arrow: :down_arrow: THIS :d...         None   None   \n",
       "6                               I 'm a trans woman .         None   None   \n",
       "7  Both of us could use a world where \" brave and...         None   None   \n",
       "\n",
       "   Causal association                                          tokenized  \n",
       "0                 0.0  [tonight, ,, I, learned, my, older, girl, will...  \n",
       "2                 0.0    [#impressive, #bigsister, #type1, #type1times2]  \n",
       "5                 0.0  [:down_arrow:, :down_arrow:, :down_arrow:, THI...  \n",
       "6                 0.0                        [I, 'm, a, trans, woman, .]  \n",
       "7                 0.0  [Both, of, us, could, use, a, world, where, \",...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Remove sentences with joke, question, negation and keep only sentences with more than 3 tokens #####\n",
    "\n",
    "print(\"Count of sentences before filtering: \", data.shape[0])\n",
    "dataFiltered = data[~data[\"Intent\"].str.contains(\"neg|joke|q\")] \n",
    "dataFiltered = dataFiltered[dataFiltered[\"tokenized\"].map(len) > 3] \n",
    "print(\"Count of sentences after filtering: \", dataFiltered.shape[0])\n",
    "print(\"Distribution:\")\n",
    "print(dataFiltered[\"Causal association\"].value_counts())\n",
    "dataFiltered.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3949356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Stratified splits ####################\n",
    "\n",
    "test_to_train_ratio = 0.1 # 10% test and 90% train\n",
    "val_to_train_ratio = 0.2 \n",
    "\n",
    "\n",
    "text = dataFiltered[\"sentence\"].values.tolist()\n",
    "labels = dataFiltered[\"Causal association\"].values.tolist()\n",
    "\n",
    "# first split the data into training and testing label in the ratio of 90:10\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(text, labels, test_size=test_to_train_ratio, stratify=labels, random_state=9)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=val_to_train_ratio, stratify=train_labels, random_state=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c084799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: Count = 16475, % of 0 = 0.8719, % of 1 = 0.1281\n",
      "Train: Count = 11861, % of 0 = 0.8718, % of 1 = 0.1282\n",
      "Val: Count = 2966, % of 0 = 0.8719, % of 1 = 0.1281\n",
      "Test: Count = 1648, % of 0 = 0.872, % of 1 = 0.128\n",
      "Balancing class wts: for 0 = 0.5735, for 1 = 3.9016\n"
     ]
    }
   ],
   "source": [
    "#################### Calculate class weights (for loss function) #########################\n",
    "\n",
    "data_count_info = pd.Series(labels).value_counts(normalize=True)\n",
    "train_count_info = pd.Series(train_labels).value_counts(normalize=True)\n",
    "val_count_info = pd.Series(val_labels).value_counts(normalize=True)\n",
    "test_count_info = pd.Series(test_labels).value_counts(normalize=True)\n",
    "\n",
    "# for class-imbalanced dataset, the class weight for a ith class\n",
    "# to be specified for balancing in the loss function is given by:\n",
    "# weight[i] = num_samples / (num_classes * num_samples[i])\n",
    "# since train_count_info obtained above has fraction of samples\n",
    "# for ith class, hence the corresponding weight calculation is:\n",
    "class_weight = (1/train_count_info)/len(train_count_info)\n",
    "\n",
    "print(\"All: Count = {}, % of 0 = {}, % of 1 = {}\".format(len(labels), *data_count_info.round(4).to_list()))\n",
    "print(\"Train: Count = {}, % of 0 = {}, % of 1 = {}\".format(len(train_labels), *train_count_info.round(4).to_list()))\n",
    "print(\"Val: Count = {}, % of 0 = {}, % of 1 = {}\".format(len(val_labels), *val_count_info.round(4).to_list()))\n",
    "print(\"Test: Count = {}, % of 0 = {}, % of 1 = {}\".format(len(test_labels), *test_count_info.round(4).to_list()))\n",
    "print(\"Balancing class wts: for 0 = {}, for 1 = {}\".format(*class_weight.round(4).to_list()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63cc2348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bae7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Create DataSet ################\n",
    "\n",
    "class TweetDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, labels, tokenizer):\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.tokenizer(self.text, padding=True, truncation=True, return_token_type_ids=True)\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        return {\n",
    "                \"input_ids\" : torch.tensor(ids[idx], dtype=torch.long)\n",
    "              , \"attention_mask\" : torch.tensor(mask[idx], dtype=torch.long)\n",
    "              , \"token_type_ids\" : torch.tensor(token_type_ids[idx], dtype=torch.long)\n",
    "              , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    \n",
    "# datasets\n",
    "train_dataset = TweetDataSet(train_texts, train_labels, tokenizer)\n",
    "val_dataset = TweetDataSet(val_texts, val_labels, tokenizer)\n",
    "test_dataset = TweetDataSet(test_texts, test_labels, tokenizer)\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "\n",
    "# data loader\n",
    "train_batch_size = 16\n",
    "val_batch_size = 16\n",
    "test_batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e92754",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8732fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_average = \"binary\" \n",
    "\n",
    "def compute_metrics(pred, labels):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels,pred, average=metrics_average)\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf123a9",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc37f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalityBERT(torch.nn.Module):\n",
    "    \"\"\" Model Bert\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CausalityBERT, self).__init__()\n",
    "        self.num_labels = 2\n",
    "        self.bert = transformers.BertModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear1 = torch.nn.Linear(768, 256)\n",
    "        self.linear2 = torch.nn.Linear(256, self.num_labels)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        _, output_1 = self.bert(input_ids, attention_mask = attention_mask, token_type_ids=token_type_ids, return_dict=False) # if output 1 is our cls token        \n",
    "        output_2 = self.dropout(output_1)\n",
    "        output_3 = self.linear1(output_2)  \n",
    "        output_4 = self.dropout(output_3)\n",
    "        output_5 = self.linear2(output_4)\n",
    "        return output_5\n",
    "    \n",
    "model = CausalityBERT() ## just load the model trained in previous round here \n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f9ac110",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### MODEL PARAMETERS ############################\n",
    "\n",
    "lr = 1e-3    \n",
    "adam_eps = 1e-8\n",
    "epochs = 1\n",
    "num_warmup_steps = 0\n",
    "\n",
    "\n",
    "# fine-tune only the task-specific parameters\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_training_steps = np.ceil(len(train_dataset)/train_batch_size)*epochs\n",
    "optim = AdamW(model.parameters(), lr=lr, eps=adam_eps)\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps) # scheduler with a linearly decreasing learning rate from the initial lr set in the optimizer to 0; after a warmup period durnig which it increases linearly from 0 to the initial lr set in the optimizer\n",
    "\n",
    "## Loss function: penalising more for class with less number of exaplmes \n",
    "loss_fn = CrossEntropyLoss(torch.tensor(class_weight.to_list()).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2363d916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                 | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================== Epoch 1 ======================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/38 [00:00<?, ?it/s]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      "  3%|█▏                                             | 1/38 [00:06<04:09,  6.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6116, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  5%|██▍                                            | 2/38 [00:13<04:10,  6.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.2237, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  8%|███▋                                           | 3/38 [00:22<04:25,  7.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(2.0967, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 11%|████▉                                          | 4/38 [00:32<04:50,  8.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5613, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 13%|██████▏                                        | 5/38 [00:41<04:56,  9.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.2402, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 16%|███████▍                                       | 6/38 [00:48<04:24,  8.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.3739, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 18%|████████▋                                      | 7/38 [00:56<04:07,  7.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5786, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 21%|█████████▉                                     | 8/38 [01:02<03:45,  7.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.7594, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 24%|███████████▏                                   | 9/38 [01:10<03:37,  7.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6252, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 26%|████████████                                  | 10/38 [01:16<03:22,  7.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6581, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 29%|█████████████▎                                | 11/38 [01:23<03:08,  7.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.7737, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 32%|██████████████▌                               | 12/38 [01:29<02:58,  6.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5811, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 34%|███████████████▋                              | 13/38 [01:36<02:52,  6.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6281, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 37%|████████████████▉                             | 14/38 [01:45<02:57,  7.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5812, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 39%|██████████████████▏                           | 15/38 [01:52<02:47,  7.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.3593, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 42%|███████████████████▎                          | 16/38 [01:59<02:39,  7.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.0037, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 45%|████████████████████▌                         | 17/38 [02:07<02:38,  7.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5846, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 47%|█████████████████████▊                        | 18/38 [02:16<02:35,  7.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.7219, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 50%|███████████████████████                       | 19/38 [02:23<02:27,  7.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6246, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 53%|████████████████████████▏                     | 20/38 [02:30<02:12,  7.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9018, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 55%|█████████████████████████▍                    | 21/38 [02:37<02:02,  7.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5897, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 58%|██████████████████████████▋                   | 22/38 [02:44<01:58,  7.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.7324, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 61%|███████████████████████████▊                  | 23/38 [03:00<02:28,  9.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.7329, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 63%|█████████████████████████████                 | 24/38 [03:10<02:19,  9.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6208, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 66%|██████████████████████████████▎               | 25/38 [03:22<02:14, 10.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6249, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 68%|███████████████████████████████▍              | 26/38 [03:30<01:58,  9.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6090, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 71%|████████████████████████████████▋             | 27/38 [03:38<01:40,  9.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9835, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 74%|█████████████████████████████████▉            | 28/38 [03:45<01:26,  8.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5733, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 76%|███████████████████████████████████           | 29/38 [03:56<01:24,  9.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6503, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 79%|████████████████████████████████████▎         | 30/38 [04:05<01:12,  9.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.7064, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 82%|█████████████████████████████████████▌        | 31/38 [04:11<00:58,  8.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6830, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 84%|██████████████████████████████████████▋       | 32/38 [04:18<00:47,  7.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.7636, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 87%|███████████████████████████████████████▉      | 33/38 [04:25<00:37,  7.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6280, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 89%|█████████████████████████████████████████▏    | 34/38 [04:32<00:29,  7.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.4215, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 92%|██████████████████████████████████████████▎   | 35/38 [04:38<00:21,  7.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5585, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 95%|███████████████████████████████████████████▌  | 36/38 [04:45<00:13,  6.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5785, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 97%|████████████████████████████████████████████▊ | 37/38 [04:52<00:06,  6.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9298, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "100%|██████████████████████████████████████████████| 38/38 [04:53<00:00,  7.72s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.2900, grad_fn=<NllLossBackward>)\n",
      "\n",
      "\tTrain loss: 0.688550565195711\n",
      "\n",
      "\ttrain acc: 0.6726973684210527\n",
      "\n",
      "\ttraining prec: 0.19157268170426067\n",
      "\n",
      "\ttraining rec: 0.4473684210526316\n",
      "\n",
      "\ttraining f1: 0.24163862453336132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/38 [00:00<?, ?it/s]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  3%|█▏                                             | 1/38 [00:06<03:46,  6.11s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  5%|██▍                                            | 2/38 [00:12<03:51,  6.42s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      "  8%|███▋                                           | 3/38 [00:18<03:28,  5.96s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 11%|████▉                                          | 4/38 [00:24<03:23,  5.99s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 13%|██████▏                                        | 5/38 [00:31<03:37,  6.60s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 16%|███████▍                                       | 6/38 [00:41<04:05,  7.67s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 18%|████████▋                                      | 7/38 [00:50<04:06,  7.96s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 21%|█████████▉                                     | 8/38 [01:04<05:02, 10.07s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 24%|███████████▏                                   | 9/38 [01:19<05:37, 11.63s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 26%|████████████                                  | 10/38 [01:32<05:34, 11.96s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 29%|█████████████▎                                | 11/38 [01:41<05:00, 11.11s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 32%|██████████████▌                               | 12/38 [01:48<04:13,  9.74s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 34%|███████████████▋                              | 13/38 [01:55<03:42,  8.89s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 37%|████████████████▉                             | 14/38 [02:02<03:24,  8.50s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 39%|██████████████████▏                           | 15/38 [02:08<02:56,  7.69s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 42%|███████████████████▎                          | 16/38 [02:15<02:44,  7.48s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 45%|████████████████████▌                         | 17/38 [02:20<02:18,  6.59s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 47%|█████████████████████▊                        | 18/38 [02:25<02:03,  6.17s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 50%|███████████████████████                       | 19/38 [02:30<01:49,  5.75s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 53%|████████████████████████▏                     | 20/38 [02:35<01:40,  5.60s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 55%|█████████████████████████▍                    | 21/38 [02:40<01:31,  5.40s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 58%|██████████████████████████▋                   | 22/38 [02:47<01:34,  5.90s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 61%|███████████████████████████▊                  | 23/38 [02:52<01:27,  5.81s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 63%|█████████████████████████████                 | 24/38 [02:58<01:21,  5.84s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 66%|██████████████████████████████▎               | 25/38 [03:04<01:15,  5.80s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 68%|███████████████████████████████▍              | 26/38 [03:09<01:07,  5.65s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 71%|████████████████████████████████▋             | 27/38 [03:16<01:06,  6.02s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 74%|█████████████████████████████████▉            | 28/38 [03:26<01:10,  7.06s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 76%|███████████████████████████████████           | 29/38 [03:35<01:09,  7.74s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 79%|████████████████████████████████████▎         | 30/38 [03:43<01:03,  7.91s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 82%|█████████████████████████████████████▌        | 31/38 [03:52<00:57,  8.16s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 84%|██████████████████████████████████████▋       | 32/38 [03:59<00:46,  7.73s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 87%|███████████████████████████████████████▉      | 33/38 [04:05<00:35,  7.20s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 89%|█████████████████████████████████████████▏    | 34/38 [04:11<00:27,  6.93s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 92%|██████████████████████████████████████████▎   | 35/38 [04:18<00:20,  6.77s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 95%|███████████████████████████████████████████▌  | 36/38 [04:23<00:12,  6.40s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 97%|████████████████████████████████████████████▊ | 37/38 [04:29<00:06,  6.24s/it]\u001b[A/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "100%|██████████████████████████████████████████████| 38/38 [04:30<00:00,  7.12s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation loss: 0.5324451139098719\n",
      "\n",
      "\tValidation acc: 0.75\n",
      "\n",
      "\tValidation prec: 0.337844611528822\n",
      "\n",
      "\tValidation rec: 0.6622807017543859\n",
      "\n",
      "\tValidation f1: 0.41466165413533834\n",
      "Validation loss decreased (inf --> 0.532445).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|████████████████████████████████████████| 1/1 [09:27<00:00, 567.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567.7661678791046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "################ TRAINING ##################\n",
    "\n",
    "# initialise the early_stopping object\n",
    "# early_stopping = EarlyStopping(patience=early_patience, path=saveModelName, verbose=True)\n",
    "early_patience = 5 # how long to wait after last time validation loss improved\n",
    "early_stopping = EarlyStopping(patience=early_patience,verbose=True)\n",
    "\n",
    "\n",
    "train_avg_loss = [] # avg training loss per epoch\n",
    "val_avg_loss = [] # avg validation loss per epoch\n",
    "train_avg_acc = [] # avg training accuracy per epoch\n",
    "val_avg_acc = [] # avg val accuracy per epoch\n",
    "n_trained_epochs = 0\n",
    "\n",
    "startTime = time.time()\n",
    "for epoch in trange(1, epochs+1, desc='Epoch'):\n",
    "    print(\"<\" + \"=\"*22 + F\" Epoch {epoch} \"+ \"=\"*22 + \">\")\n",
    "    \n",
    "    \n",
    "    ########### training eval metrics #############################\n",
    "    train_accuracy = []\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    train_prec = []\n",
    "    train_rec = []\n",
    "    train_f1 = []\n",
    "    \n",
    "    ###################################################\n",
    "    \n",
    "    for batch in tqdm(train_loader):\n",
    "        optim.zero_grad() # gradients get accumulated by default -> clear previous accumulated gradients\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        ###########################################################################\n",
    "\n",
    "        model.train()\n",
    "        logits = model(**{\"input_ids\":input_ids, \"attention_mask\":attention_mask, \"token_type_ids\":token_type_ids}) # forward pass\n",
    "        #############################################################################\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "        print(\"loss:\", loss)\n",
    "        loss.backward() # backward pass\n",
    "        optim.step()    # update parameters and take a step up using the computed gradient\n",
    "        scheduler.step()# update learning rate scheduler\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    \n",
    "        ############# Training Accuracy Measure ###################################\n",
    "\n",
    "        # move logits and labels to CPU\n",
    "        logits = logits.detach().to('cpu').numpy()\n",
    "        label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "        labels_flat = label_ids.flatten()\n",
    "\n",
    "        metrics = compute_metrics(pred_flat, labels_flat)        \n",
    "        \n",
    "        train_acc.append(metrics[\"accuracy\"])\n",
    "        train_prec.append(metrics[\"precision\"])\n",
    "        train_rec.append(metrics[\"recall\"])\n",
    "        train_f1.append(metrics[\"f1\"])\n",
    "        \n",
    "    train_avg_loss.append(np.mean(train_loss))\n",
    "    train_avg_acc.append(np.mean(train_acc))\n",
    "    print(F'\\n\\tTrain loss: {np.mean(train_loss)}')\n",
    "    print(F'\\n\\ttrain acc: {np.mean(train_acc)}')\n",
    "    print(F'\\n\\ttraining prec: {np.mean(train_prec)}')\n",
    "    print(F'\\n\\ttraining rec: {np.mean(train_rec)}')\n",
    "    print(F'\\n\\ttraining f1: {np.mean(train_f1)}')\n",
    "    \n",
    "    n_trained_epochs += 1\n",
    "    \n",
    "    ###################################################################################\n",
    "\n",
    "    \n",
    "    ## ---- Validation ------\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    val_prec = []\n",
    "    val_rec = []\n",
    "    val_f1 = []\n",
    "    \n",
    "    \n",
    "    # Evaluate data for one epoch\n",
    "    for batch in tqdm(validation_loader):\n",
    "        batch = tuple(batch[t].to(device) for t in batch)      # batch to GPU\n",
    "        b_input_ids, b_input_mask, b_token_type_ids, b_labels = batch     # unpack inputs from dataloader\n",
    "        \n",
    "        with torch.no_grad(): # tell model not to compute or store gradients -> saves memory + speeds up validation\n",
    "            ##################################################################################\n",
    "            model.eval()\n",
    "            logits = model(**{\"input_ids\":b_input_ids, \"attention_mask\":b_input_mask, \"token_type_ids\":b_token_type_ids}) # forward pass, calculates logit predictions \n",
    "\n",
    "                        \n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "        \n",
    "        # move logits and labels to CPU\n",
    "        logits = logits.detach().to('cpu').numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "        labels_flat = label_ids.flatten()\n",
    "        \n",
    "        metrics = compute_metrics(pred_flat, labels_flat)\n",
    "        val_acc.append(metrics[\"accuracy\"])\n",
    "        val_prec.append(metrics[\"precision\"])\n",
    "        val_rec.append(metrics[\"recall\"])\n",
    "        val_f1.append(metrics[\"f1\"])\n",
    "\n",
    "    val_avg_loss.append(np.mean(val_loss))\n",
    "    val_avg_acc.append(np.mean(val_acc))\n",
    "    print(F'\\n\\tValidation loss: {np.mean(val_loss)}')\n",
    "    print(F'\\n\\tValidation acc: {np.mean(val_acc)}')\n",
    "    print(F'\\n\\tValidation prec: {np.mean(val_prec)}')\n",
    "    print(F'\\n\\tValidation rec: {np.mean(val_rec)}')\n",
    "    print(F'\\n\\tValidation f1: {np.mean(val_f1)}')\n",
    "\n",
    "    # early_stopping needs the validation loss to check if it has decreased,\n",
    "    # and if it has, it will make a checkpoint of the current model\n",
    "    saveModelName = \"./trained_models/causal_tweets_finetuned-{}-epochs-lr_{}.pth\".format(n_trained_epochs-early_patience, lr) \n",
    "    early_stopping.path = saveModelName\n",
    "    early_stopping(np.average(val_loss), model)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "        \n",
    "endTime = time.time()\n",
    "print(endTime-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cc92379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot of loss with epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjSklEQVR4nO3de5QV9Znu8e9jAyICAREvoVVwRo0gF3WLGCaAQ6Io8TYyOaiIMRcXydFEM+PIJMdoYubEpWSGmIMxRGG8o4MYmYiYMRHRc7zQIBiwdURUaMXQEEFBDALv+aOqddNUd2+arm66eT5r7cWuql9Vvb8N7GfXXRGBmZlZbfu0dAFmZrZnckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEtThJj0m6pKnbtjWSfirpyvT9CElVLVxSk5L0r5ImtHQd9ikHhDWKpI1Fr+2SNhcNX7Qry4qIMyLizqZuu6skdZU0WdLKtB/L0+ED81jfLtbWExgP/CqHZR8g6WFJmyS9JenCBtpfJeldSRskTZO0bynLktRB0kxJb0oKSSNqLfpm4AeSOjRl/6zxHBDWKBHRueYFrATOKhp3b007Se1arsrSpV9Kvwf6AaOArsDngXXA4EYsr6n7/VVgTkRszmHdU4AtwMHARcAvJfWrY9mnAxOBkUBv4EjgR7uwrGeAccC7tZcdEauBV4Czd7F+y4kDwppUza4PSddIeheYLqm7pN9Kqpb0Xvq+vGieeZK+kb7/qqRnJE1K274h6YxGtu0jab6kDyQ9IWmKpHvqKH08cDhwXkS8HBHbI2JNRNwQEXPS5YWkvy5a/r9L+kk9/a6U9OWi9u0krZV0Qjo8RNL/k7Re0pKMX9TFzgCequdzfzNd90vAplJDQtL+wPnAtRGxMSKeAWYDF9cxyyXAHRGxLCLeA24gCa8GlxURWyJicjp+Wx3LnweMLqV2y58DwvJwCHAAcARwGcm/s+np8OHAZuD/1DP/ycCrwIHATcAdktSItvcBLwA9gOup+0sP4IvA3IjY2EDf6lO73/cDFxRNPx1YGxGLJPUCHgV+ks7zj8BD6a6kLP1J+lmfC0i+XLtFxNY0iNfX8fptOs/RwLaI+O+i5Swh2ZLK0i+dXtz2YEk9GrGsLJXAwF1obzlqFZv/1upsB66LiL+kw5uBh2omSvoX4Ml65n8rIn6dtr0TuJVkl8VOuyXqapvuMjoJGBkRW4BnJM2uZ509gIWldK4eO/Rb0n3Ai5I6RcSHwIUkoQXJbpY5NVsnwH9JqgDOBLKOsXQDPmhg/bdExKqagYj4cn2NU52BDbXGbQC6lNi+5n2XRiwrywckfbU9gLcgLA/VEfFRzYCkTpJ+lR60fB+YD3STVFbH/J8EQfrFCsmXz660/Szw56JxAKuo2zrg0Hqml2KHfkfEcpJfxGdJ6kSyb70mII4A/r74Vz3wN/XU8B4Nf9HW17+6bCQ53lKsK3WHUe32Ne8/aMSysnQB1u9Ce8uRA8LyUPsWwf8AHAOcHBFdgWHp+Lp2GzWF1cAB6RdzjcPqaf8EcHq6H70uHwLFyzuk1vSsWyPX7GY6B3g5DQ1IvszvjohuRa/9I+LGOtb9EskunPrssH4lpwRvrOP1WNrsv4F2ko4qmnUgsKyOdSxjx11AA4E/RcS6Riwry7HsuAvLWpADwppDF5LdTOslHQBcl/cKI+ItoAK4Pj298hTgrHpmuZvkS/shSZ+TtI+kHpK+L+nMtM1i4EJJZZJGAcNLKGUGcBrwLT7degC4h2TL4vR0eR3TA93lmUuBOSWu7xPpKcGd63idkbbZBMwCfixpf0lDScLs7joWexfwdUl9JXUH/hfw76UuS9K+kjqmgx3Sfhf/UBgOPIbtERwQ1hwmA/sBa4HngLnNtN6LgFNIdh/9BHgA+EtWw/S4wRdJTrP8L+B9kgPcBwLPp82+SxIy69Nl/6ahAtJTN58lOWX2gaLxq0i+PL8PVJOE09XU/X/yLuBMSfs1tM5G+DbJ388aki2eb0XEMgBJh6dbHIendc8lORngSeCt9HVdKctKvUryY6EX8Hj6/oh0XYcCfSnhc7XmIT8wyPYWkh4AXomI3Ldg8iDpfwNrImJyS9eSB0k/A16PiFtbuhZLOCCszZJ0EvBn4A2S3Ty/AU6JiBdbsi6z1sKnuVpbdgjJPvEeQBXJ7g6Hg1mJvAVhZmaZfJDazMwytaldTAceeGD07t27pcswM2s1Fi5cuDYiMm/x0qYConfv3lRUVLR0GWZmrYakt+qa5l1MZmaWyQFhZmaZHBBmZpapTR2DMLO26+OPP6aqqoqPPvqo4ca2k44dO1JeXk779u1LnscBYWatQlVVFV26dKF3797U/fwoyxIRrFu3jqqqKvr06VPyfN7FZGatwkcffUSPHj0cDo0giR49euzy1pcDwsxaDYdD4zXms3NAmJlZJgeEmVkD1q9fz623Nu4u5GeeeSbr168vuf3111/PpEmTGrWupuaAMDNrQH0BsW3btnrnnTNnDt26dcuhqvw5IMzMGjBx4kRef/11Bg0axNVXX828efM49dRTufDCC+nfvz8A5557LieeeCL9+vVj6tSpn8zbu3dv1q5dy5tvvsmxxx7LN7/5Tfr168dpp53G5s2b613v4sWLGTJkCAMGDOC8887jvffeA+CWW26hb9++DBgwgLFjxwLw1FNPMWjQIAYNGsTxxx/PBx98sNv99mmuZtbq/Og/l/HyO+836TL7frYr153VL3PajTfeyNKlS1m8eDEA8+bN44UXXmDp0qWfnDY6bdo0DjjgADZv3sxJJ53E+eefT48ePXZYzmuvvcb999/Pr3/9a77yla/w0EMPMW7cuDprGj9+PL/4xS8YPnw4P/zhD/nRj37E5MmTufHGG3njjTfYd999P9l9NWnSJKZMmcLQoUPZuHEjHTt2rHO5pfIWhJlZIwwePHiHawpuueUWBg4cyJAhQ1i1ahWvvfbaTvP06dOHQYMGAXDiiSfy5ptv1rn8DRs2sH79eoYPHw7AJZdcwvz58wEYMGAAF110Effccw/t2iW/84cOHcr3vvc9brnlFtavX//J+N3hLQgza3Xq+qXfnPbff/9P3s+bN48nnniCZ599lk6dOjFixIjMaw723XffT96XlZU1uIupLo8++ijz589n9uzZ3HDDDSxbtoyJEycyevRo5syZw5AhQ3jiiSf43Oc+16jl1/AWhJlZA7p06VLvPv0NGzbQvXt3OnXqxCuvvMJzzz232+v8zGc+Q/fu3Xn66acBuPvuuxk+fDjbt29n1apVnHrqqdx0002sX7+ejRs38vrrr9O/f3+uueYaCoUCr7zyym7X4C0IM7MG9OjRg6FDh3LcccdxxhlnMHr06B2mjxo1ittuu40BAwZwzDHHMGTIkCZZ75133smECRP48MMPOfLII5k+fTrbtm1j3LhxbNiwgYjgqquuolu3blx77bU8+eSTlJWV0bdvX84444zdXn+uz6SWNAr4OVAG3B4RN2a0GQFMBtoDayNieDr+KuAbQAB/BC6NiHqvEy8UCuEHBpm1TZWVlRx77LEtXUarlvUZSloYEYWs9rntYpJUBkwBzgD6AhdI6lurTTfgVuDsiOgH/H06vhfwHaAQEceRBMzYvGo1M7Od5XkMYjCwPCJWRMQWYAZwTq02FwKzImIlQESsKZrWDthPUjugE/BOjrWamVkteQZEL2BV0XBVOq7Y0UB3SfMkLZQ0HiAi3gYmASuB1cCGiPhd1kokXSapQlJFdXV1k3fCzGxvlWdAZN06sPYBj3bAicBo4HTgWklHS+pOsrXRB/gssL+kzKtJImJqRBQiotCzZ8+mq97MbC+X51lMVcBhRcPl7LybqIrkwPQmYJOk+cDAdNobEVENIGkW8HngnhzrNTOzInluQSwAjpLUR1IHkoPMs2u1eQT4gqR2kjoBJwOVJLuWhkjqpOQm5iPT8WZm1kxy24KIiK2SLgceJzkLaVpELJM0IZ1+W0RUSpoLvARsJzkVdimApJnAImAr8CIwNWs9ZmZ7os6dO7Nx48aSx++Jcr1QLiLmAHNqjbut1vDNwM0Z814HXJdnfWZmVjffasPMrAHXXHPNDs+DuP766/nZz37Gxo0bGTlyJCeccAL9+/fnkUceKXmZEcHVV1/NcccdR//+/XnggQcAWL16NcOGDWPQoEEcd9xxPP3002zbto2vfvWrn7T9t3/7tybvYxbfasPMWp/HJsK7f2zaZR7SH87Y6WYPAIwdO5Yrr7ySb3/72wA8+OCDzJ07l44dO/Lwww/TtWtX1q5dy5AhQzj77LNLev7zrFmzWLx4MUuWLGHt2rWcdNJJDBs2jPvuu4/TTz+dH/zgB2zbto0PP/yQxYsX8/bbb7N06VKAXXpC3e5wQJiZNeD4449nzZo1vPPOO1RXV9O9e3cOP/xwPv74Y77//e8zf/589tlnH95++23+9Kc/ccghhzS4zGeeeYYLLriAsrIyDj74YIYPH86CBQs46aST+NrXvsbHH3/Mueeey6BBgzjyyCNZsWIFV1xxBaNHj+a0005rhl47IMysNarjl36exowZw8yZM3n33Xc/eYrbvffeS3V1NQsXLqR9+/b07t078zbfWeq6D96wYcOYP38+jz76KBdffDFXX30148ePZ8mSJTz++ONMmTKFBx98kGnTpjVZ3+riYxBmZiUYO3YsM2bMYObMmYwZMwZIbvN90EEH0b59e5588kneeuutkpc3bNgwHnjgAbZt20Z1dTXz589n8ODBvPXWWxx00EF885vf5Otf/zqLFi1i7dq1bN++nfPPP58bbriBRYsW5dXNHXgLwsysBP369eODDz6gV69eHHrooQBcdNFFnHXWWRQKBQYNGrRLD+g577zzePbZZxk4cCCSuOmmmzjkkEO48847ufnmm2nfvj2dO3fmrrvu4u233+bSSy9l+/btAPz0pz/NpY+15Xq77+bm232btV2+3ffu22Nu921mZq2bA8LMzDI5IMys1WhLu8SbW2M+OweEmbUKHTt2ZN26dQ6JRogI1q1bR8eOHXdpPp/FZGatQnl5OVVVVfjBYI3TsWNHysvLd2keB4SZtQrt27enT58+LV3GXsW7mMzMLJMDwszMMjkgzMwsU64BIWmUpFclLZc0sY42IyQtlrRM0lNF47tJminpFUmVkk7Js1YzM9tRbgepJZUBU4AvAVXAAkmzI+LlojbdgFuBURGxUtJBRYv4OTA3Isakz7TulFetZma2szy3IAYDyyNiRURsAWYA59RqcyEwKyJWAkTEGgBJXYFhwB3p+C0RsT7HWs3MrJY8A6IXsKpouCodV+xooLukeZIWShqfjj8SqAamS3pR0u2S9s9aiaTLJFVIqvD50WZmTSfPgMh65l7tSyDbAScCo4HTgWslHZ2OPwH4ZUQcD2wCMo9hRMTUiChERKFnz55NVryZ2d4uz4CoAg4rGi4H3sloMzciNkXEWmA+MDAdXxURz6ftZpIEhpmZNZM8A2IBcJSkPulB5rHA7FptHgG+IKmdpE7AyUBlRLwLrJJ0TNpuJPAyZmbWbHI7iykitkq6HHgcKAOmRcQySRPS6bdFRKWkucBLwHbg9ohYmi7iCuDeNFxWAJfmVauZme3MT5QzM9uL+YlyZma2yxwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZplyDQhJoyS9Kmm5pIl1tBkhabGkZZKeqjWtTNKLkn6bZ51mZraz3J5JLakMmAJ8CagCFkiaHREvF7XpBtwKjIqIlZIOqrWY7wKVQNe86jQzs2x5bkEMBpZHxIqI2ALMAM6p1eZCYFZErASIiDU1EySVA6OB23Os0czM6pBnQPQCVhUNV6Xjih0NdJc0T9JCSeOLpk0G/gnYXt9KJF0mqUJSRXV1dROUbWZmkOMuJkAZ4yJj/ScCI4H9gGclPUcSHGsiYqGkEfWtJCKmAlMBCoVC7eWbmVkj5RkQVcBhRcPlwDsZbdZGxCZgk6T5wEDgBOBsSWcCHYGuku6JiHE51mtmZkXy3MW0ADhKUh9JHYCxwOxabR4BviCpnaROwMlAZUT8c0SUR0TvdL4/OBzMzJpXblsQEbFV0uXA40AZMC0ilkmakE6/LSIqJc0FXiI51nB7RCzNqyYzMyudItrObvtCoRAVFRUtXYaZWashaWFEFLKm+UpqMzPL5IAwM7NMDggzM8vkgDAzs0wOCDMzy+SAMDOzTA4IMzPL5IAwM7NMDQaEpL+StG/6foSk76TPcTAzszaslC2Ih4Btkv4auAPoA9yXa1VmZtbiSgmI7RGxFTgPmBwRVwGH5luWmZm1tFIC4mNJFwCXADXPhm6fX0lmZrYnKCUgLgVOAf4lIt6Q1Ae4J9+yzMyspTV4u++IeBn4DoCk7kCXiLgx78LMzKxllXIW0zxJXSUdACwBpkv61/xLMzOzllTKLqbPRMT7wN8B0yPiROCL+ZZlZmYtrZSAaCfpUOArfHqQuiSSRkl6VdJySRPraDNC0mJJyyQ9lY47TNKTkirT8d/dlfWamdnuK+WRoz8meWzo/42IBZKOBF5raCZJZcAU4EtAFbBA0uz0mEZNm27ArcCoiFgp6aB00lbgHyJikaQuwEJJ/1U8r5mZ5auUg9T/AfxH0fAK4PwSlj0YWJ62R9IM4Byg+Ev+QmBWRKxMl70m/XM1sDp9/4GkSqBXrXnNzCxHpRykLpf0sKQ1kv4k6SFJ5SUsuxewqmi4Kh1X7Gige3ogfKGk8Rnr7w0cDzxfR32XSaqQVFFdXV1CWWZmVopSjkFMB2YDnyX5gv/PdFxDlDEuag23A04ERgOnA9dKOvqTBUidSW71cWV6oHznBUZMjYhCRBR69uxZQllmZlaKUgKiZ0RMj4it6evfgVK+iauAw4qGy4F3MtrMjYhNEbEWmA8MBJDUniQc7o2IWSWsz8zMmlApAbFW0jhJZelrHLCuhPkWAEdJ6iOpAzCWZEuk2CPAFyS1k9QJOBmolCSSGwNWRoSvuTAzawGlBMTXSE5xfZfkwPEYkttv1Cu9wd/lJGdAVQIPRsQySRMkTUjbVAJzgZeAF4DbI2IpMBS4GPjb9BTYxZLO3OXemZlZoymi9mGBEmaSJkXEP+ZQz24pFApRUVHR0mWYmbUakhZGRCFrWmOfKPeV3ajHzMxagcYGRNYZSmZm1obUeaFcenO+zEk4IMzM2rz6rqReSHLdQlYYbMmnHDMz21PUGRAR0ac5CzEzsz1LY49BmJlZG+eAMDOzTA4IMzPLVMrzIGqe7XBwcfuaW3SbmVnb1GBASLoCuA74E7A9HR3AgBzrMjOzFlbKFsR3gWMiopQb9JmZWRtRyjGIVcCGvAsxM7M9SylbECuAeZIeBf5SM9K34TYza9tKCYiV6atD+jIzs71AgwERET9qjkLMzGzPUt/N+iZHxJWS/pOdnyVNRJyda2VmZtai6tuCuDv9c1JjFy5pFPBzoIzkaXE3ZrQZAUwG2gNrI2J4qfOamVl+6rtZ38L0z6cas+D04ropwJeAKmCBpNkR8XJRm27ArcCoiFgp6aBS5zUzs3w1eJqrpKMkzZT0sqQVNa8Slj0YWB4RKyJiCzADOKdWmwuBWTVXZUfEml2Y18zMclTKdRDTgV8CW4FTgbv4dPdTfXqRXENRoyodV+xooLukeZIWShq/C/MCIOkySRWSKqqrq0soy8zMSlFKQOwXEb8HFBFvRcT1wN+WMF/Wg4ZqH+xuB5wIjAZOB66VdHSJ8yYjI6ZGRCEiCj179iyhLDMzK0Up10F8JGkf4DVJlwNvAweVMF8VcFjRcDnwTkabtRGxCdgkaT4wsMR5zcwsR6VsQVwJdAK+Q/JrfxxwSQnzLQCOktRHUgdgLDC7VptHgC9IaiepE3AyUFnivGZmlqN6tyDSs4m+EhFXAxuBS0tdcERsTbc4Hic5VXVaRCyTNCGdfltEVEqaC7xEcqfY2yNiabrunebd9e6ZmVljKSJz1z6S2qVf8n8ARkZdDfcghUIhKioqWroMM7NWQ9LCiChkTatvC+IF4ATgReARSf8BbKqZGBGzmrRKMzPbo5RykPoAYB3JmUtBcoZRAA4IM7M2rL6AOEjS94ClfBoMNfb43U1mZrZ76guIMqAzu3BNgpmZtR31BcTqiPhxs1ViZmZ7lPqug8jacjAzs71EfQExstmqMDOzPU6dARERf27OQszMbM9Syq02zMxsL+SAMDOzTA4IMzPL5IAwM7NMDggzM8vkgDAzs0wOCDMzy+SAMDOzTA4IMzPLlGtASBol6VVJyyVNzJg+QtIGSYvT1w+Lpl0laZmkpZLul9Qxz1rNzGxHuQVE+jzrKcAZQF/gAkl9M5o+HRGD0teP03l7Ad8BChFxHMmtx8fmVauZme0szy2IwcDyiFgREVuAGcA5uzB/O2A/Se2ATsA7OdRoZmZ1yDMgegGrioar0nG1nSJpiaTHJPUDiIi3gUnASmA1sCEifpe1EkmXSaqQVFFdXd20PTAz24vlGRClPIluEXBERAwEfgH8BkBSd5KtjT7AZ4H9JY3LWklETI2IQkQUevbs2VS1m5nt9fIMiCrgsKLhcmrtJoqI9yNiY/p+DtBe0oHAF4E3IqI6Ij4GZgGfz7FWMzOrJc+AWAAcJamPpA4kB5lnFzeQdIgkpe8Hp/WsI9m1NERSp3T6SKAyx1rNzKyW+p5JvVsiYquky4HHSc5CmhYRyyRNSKffBowBviVpK7AZGBsRATwvaSbJLqitwIvA1LxqNTOznSn5Pm4bCoVCVFRUtHQZZmathqSFEVHImuYrqc3MLJMDwszMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzMLJMDwszMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzMLJMDwszMMjkgzMwskwPCzMwy5RoQkkZJelXSckkTM6aPkLRB0uL09cOiad0kzZT0iqRKSafkWauZme0ot0eOSioDpgBfAqqABZJmR8TLtZo+HRFfzljEz4G5ETEmfaZ1p7xqNTOzneW5BTEYWB4RKyJiCzADOKeUGSV1BYYBdwBExJaIWJ9XoWZmtrM8A6IXsKpouCodV9spkpZIekxSv3TckUA1MF3Si5Jul7R/1kokXSapQlJFdXV1k3bAzGxvlmdAKGNc1BpeBBwREQOBXwC/Sce3A04AfhkRxwObgJ2OYQBExNSIKEREoWfPnk1SuJmZ5RsQVcBhRcPlwDvFDSLi/YjYmL6fA7SXdGA6b1VEPJ82nUkSGGZm1kzyDIgFwFGS+qQHmccCs4sbSDpEktL3g9N61kXEu8AqScekTUcCtQ9um5lZjnI7iykitkq6HHgcKAOmRcQySRPS6bcBY4BvSdoKbAbGRkTNbqgrgHvTcFkBXJpXrWZmtjN9+n3c+hUKhaioqGjpMszMWg1JCyOikDXNV1KbmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZco1ICSNkvSqpOWSJmZMHyFpg6TF6euHtaaXSXpR0m/zrNPMzHaW2yNHJZUBU4AvAVXAAkmzI6L2s6Wfjogv17GY7wKVQNe86jQzs2x5bkEMBpZHxIqI2ALMAM4pdWZJ5cBo4Pac6jMzs3rkGRC9gFVFw1XpuNpOkbRE0mOS+hWNnwz8E7C9vpVIukxShaSK6urq3a3ZzMxSeQaEMsZFreFFwBERMRD4BfAbAElfBtZExMKGVhIRUyOiEBGFnj177mbJZmZWI8+AqAIOKxouB94pbhAR70fExvT9HKC9pAOBocDZkt4k2TX1t5LuybFWMzOrJc+AWAAcJamPpA7AWGB2cQNJh0hS+n5wWs+6iPjniCiPiN7pfH+IiHE51mpmZrXkdhZTRGyVdDnwOFAGTIuIZZImpNNvA8YA35K0FdgMjI2I2ruhzMysBagtfR8XCoWoqKho6TLMzFoNSQsjopA1zVdSm5lZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllalO3+5ZUDbzV0nXsogOBtS1dRDNzn/cO7nPrcEREZD6vuU0FRGskqaKue7G3Ve7z3sF9bv28i8nMzDI5IMzMLJMDouVNbekCWoD7vHdwn1s5H4MwM7NM3oIwM7NMDggzM8vkgMiRpFGSXpW0XNLEjOndJT0s6SVJL0g6rmhaN0kzJb0iqVLSKc1bfePsZp+vkrRM0lJJ90vq2LzV7zpJ0yStkbS0jumSdEv6ebwk6YSiafV+VnuqxvZZ0mGSnkz/PS+T9N3mrbzxdufvOZ1eJulFSb9tnoqbSET4lcMLKANeB44EOgBLgL612twMXJe+/xzw+6JpdwLfSN93ALq1dJ/y7DPQC3gD2C8dfhD4akv3qYQ+DwNOAJbWMf1M4DFAwBDg+VI/qz31tRt9PhQ4IX3fBfjvtt7nounfA+4DftvSfdmVl7cg8jMYWB4RKyJiCzADOKdWm77A7wEi4hWgt6SDJXUl+Qd5RzptS0Ssb7bKG6/RfU6ntQP2k9QO6AS80zxlN15EzAf+XE+Tc4C7IvEc0E3SoZT2We2RGtvniFgdEYvSZXwAVJL8MNjj7cbfM5LKgdHA7flX2rQcEPnpBawqGq5i5/8MS4C/A5A0GDgCKCf5VVkNTE83S2+XtH/+Je+2Rvc5It4GJgErgdXAhoj4Xe4V56+uz6SUz6q1arBvknoDxwPPN19Zuaqvz5OBfwK2N3NNu80BkR9ljKt9TvGNQHdJi4ErgBeBrSS/pE8AfhkRxwObgNawj7rRfZbUneRXWB/gs8D+ksblWGtzqeszKeWzaq3q7ZukzsBDwJUR8X6zVZWvzD5L+jKwJiIWNndBTaFdSxfQhlUBhxUNl1Nrl0n6n+NSSA5ykeyDf4Nk90pVRNT8uppJ6wiI3enz6cAbEVGdTpsFfB64J/+yc1XXZ9KhjvFtQZ3/DiS1JwmHeyNiVgvUlpe6+jwGOFvSmUBHoKukeyKiVfz48RZEfhYAR0nqI6kDMBaYXdwgPVOpQzr4DWB+RLwfEe8CqyQdk04bCbzcXIXvhkb3mWTX0hBJndLgGEmyj7q1mw2MT89yGUKy62w1JXxWrVhmn9O/1zuAyoj415Ytscll9jki/jkiyiOiN8nf8R9aSziAtyByExFbJV0OPE5yxsq0iFgmaUI6/TbgWOAuSdtIAuDrRYu4Arg3/fJYQfqre0+2O32OiOclzQQWkexme5FWcNsCSfcDI4ADJVUB1wHt4ZP+ziE5w2U58CHp32Ndn1Wzd6ARGttnYChwMfDHdBcjwPcjYk6zFd9Iu9HnVs232jAzs0zexWRmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmLUjSiFZ3h0/bazggzMwskwPCrASSxil5fsViSb9K7++/UdLPJC2S9HtJPdO2gyQ9lz4X4OH0PlNI+mtJT0haks7zV+niO+vTZ3/cm15xjKQbJb2cLmdSC3Xd9mIOCLMGSDoW+B/A0IgYBGwDLgL2BxZFxAnAUyRX1wLcBVwTEQOAPxaNvxeYEhEDSe4ztTodfzxwJcmt0I8Ehko6ADgP6Jcu5yd59tEsiwPCrGEjgROBBektIkaSfJFvBx5I29wD/I2kz5A83OmpdPydwDBJXYBeEfEwQER8FBEfpm1eiIiqiNgOLAZ6A+8DHwG3S/o7kts3mDUrB4RZwwTcGRGD0tcxEXF9Rrv67luTdTvoGn8per8NaBcRW0keKvQQcC4wd9dKNtt9Dgizhv0eGCPpIABJB0g6guT/z5i0zYXAMxGxAXhP0hfS8RcDT6V3rK2SdG66jH0ldaprhekzEz6T3sjuSmBQk/fKrAG+m6tZAyLiZUn/C/idpH2Aj4H/SfIgp36SFgIbSI5TAFwC3JYGQPGdeC8GfiXpx+ky/r6e1XYBHpHUkWTr46om7pZZg3w3V7NGkrQxIjq3dB1mefEuJjMzy+QtCDMzy+QtCDMzy+SAMDOzTA4IMzPL5IAwM7NMDggzM8v0/wG1Ru79yex1sgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Plot of loss with epochs\")\n",
    "plt.plot(range(1, n_trained_epochs+1), train_avg_loss, label=\"train loss\")\n",
    "plt.plot(range(1, n_trained_epochs+1), val_avg_loss, label=\"val loss\")\n",
    "plt.title(\"Training Curve (lr={})\".format(lr))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd9939d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, n_trained_epochs+1), train_avg_acc, label=\"train acc\")\n",
    "plt.plot(range(1, n_trained_epochs+1), val_avg_acc, label=\"val acc\")\n",
    "plt.title(\"Training Curve (lr={})\".format(lr))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Train/val Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a206eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                       | 0/52 [00:00<?, ?it/s]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "  2%|▉                                              | 1/52 [00:20<17:43, 20.86s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "  4%|█▊                                             | 2/52 [00:36<15:04, 18.08s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "  6%|██▋                                            | 3/52 [00:54<14:34, 17.84s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "  8%|███▌                                           | 4/52 [01:20<16:58, 21.21s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 10%|████▌                                          | 5/52 [01:43<17:02, 21.76s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 12%|█████▍                                         | 6/52 [02:06<17:00, 22.18s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 13%|██████▎                                        | 7/52 [02:45<20:44, 27.65s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 15%|███████▏                                       | 8/52 [03:37<26:01, 35.49s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 17%|████████▏                                      | 9/52 [04:31<29:28, 41.13s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 19%|████████▊                                     | 10/52 [05:16<29:36, 42.29s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 21%|█████████▋                                    | 11/52 [06:22<33:56, 49.67s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 23%|██████████▌                                   | 12/52 [06:53<29:15, 43.88s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 25%|███████████▌                                  | 13/52 [07:21<25:20, 38.98s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 27%|████████████▍                                 | 14/52 [08:00<24:44, 39.06s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 29%|█████████████▎                                | 15/52 [08:40<24:15, 39.33s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 31%|██████████████▏                               | 16/52 [09:25<24:36, 41.02s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 33%|███████████████                               | 17/52 [09:43<20:02, 34.35s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 35%|███████████████▉                              | 18/52 [10:01<16:39, 29.40s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 37%|████████████████▊                             | 19/52 [10:19<14:15, 25.92s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 38%|█████████████████▋                            | 20/52 [10:37<12:35, 23.61s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 40%|██████████████████▌                           | 21/52 [10:59<11:56, 23.12s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 42%|███████████████████▍                          | 22/52 [11:19<11:00, 22.03s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 44%|████████████████████▎                         | 23/52 [11:38<10:11, 21.10s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 46%|█████████████████████▏                        | 24/52 [11:58<09:41, 20.78s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 48%|██████████████████████                        | 25/52 [12:21<09:40, 21.51s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 50%|███████████████████████                       | 26/52 [12:41<09:04, 20.93s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 52%|███████████████████████▉                      | 27/52 [12:58<08:19, 19.98s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 54%|████████████████████████▊                     | 28/52 [13:15<07:36, 19.03s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 56%|█████████████████████████▋                    | 29/52 [13:31<06:51, 17.91s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 58%|██████████████████████████▌                   | 30/52 [13:47<06:26, 17.58s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 60%|███████████████████████████▍                  | 31/52 [14:07<06:22, 18.20s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 62%|████████████████████████████▎                 | 32/52 [14:25<06:04, 18.22s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 63%|█████████████████████████████▏                | 33/52 [14:48<06:12, 19.62s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 65%|██████████████████████████████                | 34/52 [15:07<05:47, 19.31s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 67%|██████████████████████████████▉               | 35/52 [15:25<05:21, 18.90s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 69%|███████████████████████████████▊              | 36/52 [15:41<04:48, 18.02s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 71%|████████████████████████████████▋             | 37/52 [15:56<04:19, 17.30s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 73%|█████████████████████████████████▌            | 38/52 [16:12<03:54, 16.74s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 75%|██████████████████████████████████▌           | 39/52 [16:28<03:35, 16.54s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 77%|███████████████████████████████████▍          | 40/52 [16:44<03:16, 16.35s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 79%|████████████████████████████████████▎         | 41/52 [16:59<02:55, 15.93s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 81%|█████████████████████████████████████▏        | 42/52 [17:14<02:36, 15.66s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 83%|██████████████████████████████████████        | 43/52 [17:29<02:19, 15.52s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 85%|██████████████████████████████████████▉       | 44/52 [17:45<02:06, 15.76s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 87%|███████████████████████████████████████▊      | 45/52 [18:01<01:49, 15.66s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 88%|████████████████████████████████████████▋     | 46/52 [18:15<01:32, 15.42s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 90%|█████████████████████████████████████████▌    | 47/52 [18:30<01:16, 15.23s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 92%|██████████████████████████████████████████▍   | 48/52 [18:47<01:02, 15.58s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 94%|███████████████████████████████████████████▎  | 49/52 [19:01<00:45, 15.28s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 96%|████████████████████████████████████████████▏ | 50/52 [19:16<00:30, 15.14s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      " 98%|█████████████████████████████████████████████ | 51/52 [19:31<00:15, 15.05s/it]/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_10039/1071203384.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "100%|██████████████████████████████████████████████| 52/52 [19:38<00:00, 22.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\ttest loss: nan\n",
      "\n",
      "\ttest acc: 0.7355769230769231\n",
      "\n",
      "\ttest prec: 0.26398777504546733\n",
      "\n",
      "\ttest rec: 0.5991834554334554\n",
      "\n",
      "\ttest f1: 0.35182295592661156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/adrianahne/miniconda3/envs/dataCraft/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#loss_fn = CrossEntropyLoss()\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "test_prec = []\n",
    "test_rec = []\n",
    "test_f1 = []\n",
    "\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    batch = tuple(batch[t].to(device) for t in batch)      # batch to GPU\n",
    "    b_input_ids, b_input_mask, b_token_type_ids, b_labels = batch     # unpack inputs from dataloader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        logits = model(**{\"input_ids\":b_input_ids, \"attention_mask\":b_input_mask, \"token_type_ids\":b_token_type_ids}) # forward pass, calculates logit predictions \n",
    "    \n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().to('cpu').numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "    labels_flat = label_ids.flatten()\n",
    "    \n",
    "    metrics = compute_metrics(pred_flat, labels_flat)\n",
    "    test_acc.append(metrics[\"accuracy\"])\n",
    "    test_prec.append(metrics[\"precision\"])\n",
    "    test_rec.append(metrics[\"recall\"])\n",
    "    test_f1.append(metrics[\"f1\"])\n",
    "\n",
    "    \n",
    "print(F'\\n\\ttest loss: {np.mean(test_loss)}')\n",
    "print(F'\\n\\ttest acc: {np.mean(test_acc)}')\n",
    "print(F'\\n\\ttest prec: {np.mean(test_prec)}')\n",
    "print(F'\\n\\ttest rec: {np.mean(test_rec)}')\n",
    "print(F'\\n\\ttest f1: {np.mean(test_f1)}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c8e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b93e4d11",
   "metadata": {},
   "source": [
    "## Apply classifier on diabetes tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9858c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from emoji import demojize\n",
    "import re\n",
    "\n",
    "# Define DataSet class again, just without the labels parameter this time.\n",
    "\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "# https://huggingface.co/vinai/bertweet-base\n",
    "def normalizeToken(token):\n",
    "    lowercased_token = token.lower()\n",
    "    if token.startswith(\"@\"):\n",
    "        return \"@USER\"\n",
    "    elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
    "        return \"HTTPURL\"\n",
    "    elif len(token) == 1:\n",
    "        return demojize(token)\n",
    "    else:\n",
    "        if token == \"’\":\n",
    "            return \"'\"\n",
    "        elif token == \"…\":\n",
    "            return \"...\"\n",
    "        else:\n",
    "            return token\n",
    "\n",
    "def normalizeTweet(tweet):\n",
    "\n",
    "    tokens = tweet_tokenizer.tokenize(tweet.replace(\"’\", \"'\").replace(\"…\", \"...\"))\n",
    "    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n",
    "\n",
    "    normTweet = normTweet.replace(\"cannot \", \"can not \").replace(\"n't \", \" n't \").replace(\"n 't \", \" n't \").replace(\"ca n't\", \"can't\").replace(\"ai n't\", \"ain't\")\n",
    "    normTweet = normTweet.replace(\"'m \", \" 'm \").replace(\"'re \", \" 're \").replace(\"'s \", \" 's \").replace(\"'ll \", \" 'll \").replace(\"'d \", \" 'd \").replace(\"'ve \", \" 've \")\n",
    "    normTweet = normTweet.replace(\" p . m .\", \"  p.m.\") .replace(\" p . m \", \" p.m \").replace(\" a . m .\", \" a.m.\").replace(\" a . m \", \" a.m \")\n",
    "\n",
    "    normTweet = re.sub(r\",([0-9]{2,4}) , ([0-9]{2,4})\", r\",\\1,\\2\", normTweet)\n",
    "    normTweet = re.sub(r\"([0-9]{1,3}) / ([0-9]{2,4})\", r\"\\1/\\2\", normTweet)\n",
    "    normTweet = re.sub(r\"([0-9]{1,3})- ([0-9]{2,4})\", r\"\\1-\\2\", normTweet)\n",
    "    \n",
    "    return \" \".join(normTweet.split())\n",
    "\n",
    "\n",
    "class TweetDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, tokenizer):\n",
    "        self.text = text\n",
    "        #self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.tokenizer(self.text, padding=True, truncation=True, return_token_type_ids=True)\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        return {\n",
    "                \"input_ids\" : torch.tensor(ids[idx], dtype=torch.long)\n",
    "              , \"attention_mask\" : torch.tensor(mask[idx], dtype=torch.long)\n",
    "              , \"token_type_ids\" : torch.tensor(token_type_ids[idx], dtype=torch.long)\n",
    "             # , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    \n",
    "softmax = torch.nn.Softmax(-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2549000",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### LOAD diabetes tweets #################\n",
    "\n",
    "data_path = \"data/diabetes_tweets_normalized.csv\" \n",
    "diabetes_tweets = pd.read_csv(data_path, sep=\";\")#.sample(n=1000, random_state=1)\n",
    "print(\"N:\", diabetes_tweets.shape)\n",
    "diabetes_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5649b467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/vinai/bertweet-base/resolve/main/config.json from cache at /Users/adrianahne/.cache/huggingface/transformers/356366feedcea0917e30f7f235e1e062ffc2d28138445d5672a184be756c8686.a2b6026e688d1b19cebc0981d8f3a5b1668eabfda55b2c42049d5eac0bc8cb2d\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/vinai/bertweet-base/resolve/main/vocab.txt from cache at /Users/adrianahne/.cache/huggingface/transformers/9a877d0d57efbfeae96fec396a35595dc8c4685fe2b7b2049c6c094e24a0e8bf.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n",
      "loading file https://huggingface.co/vinai/bertweet-base/resolve/main/bpe.codes from cache at /Users/adrianahne/.cache/huggingface/transformers/1c2d05a06ac61a063ad62a7590731a28cc62f58e2802c76b5f993165f25894a9.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n",
      "loading file https://huggingface.co/vinai/bertweet-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/vinai/bertweet-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/vinai/bertweet-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading file https://huggingface.co/vinai/bertweet-base/resolve/main/tokenizer.json from cache at None\n",
      "loading configuration file https://huggingface.co/vinai/bertweet-base/resolve/main/config.json from cache at /Users/adrianahne/.cache/huggingface/transformers/356366feedcea0917e30f7f235e1e062ffc2d28138445d5672a184be756c8686.a2b6026e688d1b19cebc0981d8f3a5b1668eabfda55b2c42049d5eac0bc8cb2d\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "Adding <mask> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/vinai/bertweet-base/resolve/main/config.json from cache at /Users/adrianahne/.cache/huggingface/transformers/356366feedcea0917e30f7f235e1e062ffc2d28138445d5672a184be756c8686.a2b6026e688d1b19cebc0981d8f3a5b1668eabfda55b2c42049d5eac0bc8cb2d\n",
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/vinai/bertweet-base/resolve/main/pytorch_model.bin from cache at /Users/adrianahne/.cache/huggingface/transformers/4e07e2989cb95a6f63c704a7170b48e6e663cc203c05db424e47f4d75562cf0e.7b2adda243ecb4b085eb2d22ef1b2cd12a882a43bbb13a34c11e10f960b9bfc3\n",
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing BertModel: ['roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'lm_head.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.5.output.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'pooler.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'pooler.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './model-causal-tweet/model_4_finetuned-8-epochs-lr_1e-05.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kr/xl7k0ks17bq191p_5d8z3x700000gn/T/ipykernel_2133/4002853522.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mcausal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./model-causal-tweet/model_4_finetuned-8-epochs-lr_1e-05.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCausalityBERT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcausal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dataCraft/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dataCraft/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dataCraft/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model-causal-tweet/model_4_finetuned-8-epochs-lr_1e-05.pth'"
     ]
    }
   ],
   "source": [
    "############# LOAD TOKENIZER  +++++++++++++++\n",
    "\n",
    "bert_model = \"vinai/bertweet-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32162cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# load fine-tuned model ###################\n",
    "\n",
    "# Or keep the model you trained and test it !\n",
    "\n",
    "\n",
    "# Define here the model architecture of the fine-tuned model\n",
    "class CausalityBERT(torch.nn.Module):\n",
    "    \"\"\" Model Bert\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CausalityBERT, self).__init__()\n",
    "        self.num_labels = 2\n",
    "        self.bert = transformers.BertModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear1 = torch.nn.Linear(768, 256)\n",
    "        self.linear2 = torch.nn.Linear(256, self.num_labels)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        _, output_1 = self.bert(input_ids, attention_mask = attention_mask, token_type_ids=token_type_ids, return_dict=False) # if output 1 is our cls token        \n",
    "        output_2 = self.dropout(output_1)\n",
    "        output_3 = self.linear1(output_2)  \n",
    "        output_4 = self.dropout(output_3)\n",
    "        output_5 = self.linear2(output_4)\n",
    "        return output_5\n",
    "\n",
    "\n",
    "\n",
    "finetuned_model = \"models/causal_sentence_model-lr_1e-05.pth\"\n",
    "\n",
    "model = CausalityBERT() ## just load the model trained in previous round here \n",
    "model.load_state_dict(torch.load(finetuned_model, map_location='cpu')) # load model trained in previous round\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946906aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Split tweets to sentences ###############\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    \"\"\" Split tweet into sentences \"\"\"\n",
    "    \n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\"..\", \"<POINTPOINT>\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"<POINTPOINT>\", \"..\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    sentences = [s  for s in sentences if s != \"\"]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "tweetsSplit = diabetes_tweets[\"text\"].map(lambda text: split_into_sentences(normalizeTweet(text)))\n",
    "print(tweetsSplit.shape[0])\n",
    "\n",
    "sentences = tweetsSplit.explode()\n",
    "print(\"tweets to sentences:\", sentences.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6addf719",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Exclude questions and sentences with less than 5 words \n",
    "# and sentences without diabetes related keyword #################\n",
    "\n",
    "\n",
    "trainingData = sentences[sentences.str.split(\" \").str.len() > 5] # keep only sentence with more than 3 tokens\n",
    "trainingData = trainingData[~trainingData.str.endswith(\"?\")]\n",
    "#trainingData = trainingData[trainingData.str.contains(\"|\".join(diabetes_keywords))]\n",
    "\n",
    "print(\"N sentences with > 5 words & no question & all with diabetes keyword:\", trainingData.shape)\n",
    "\n",
    "text = trainingData.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fd1a5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Get DataSet + DataLoader ###############\n",
    "\n",
    "batch_size = 128\n",
    "test_dataset = TweetDataSet(text, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d523aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    per_device_eval_batch_size=batch_size,   # batch size for evaluation\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "# we only use Trainer for inference\n",
    "trainer = Trainer(model=model, args=training_args)\n",
    "print(\"build trainer on device:\", training_args.device, \"with n gpus:\", training_args.n_gpu)\n",
    "\n",
    "logits = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a98ab405",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.Series(torch.argmax(torch.Tensor(logits.predictions),dim=1).flatten())\n",
    "probas = pd.Series(torch.softmax(torch.Tensor(logits.predictions), dim = -1)[...,-1:].to('cpu').numpy().squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0694c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "causalDF = pd.DataFrame({\"text\":text, \"causal_predictions\": predictions, \"proba\":probas})\n",
    "print(\"causal sentences:\", causalDF.shape[0])\n",
    "print(causalDF.causal_predictions.value_counts())\n",
    "causalDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ddc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in causalDF[0:100].iterrows():\n",
    "    print(row[\"text\"])\n",
    "    print(\"pred:\", row[\"causal_predictions\"], \"proba\", row[\"proba\"])\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b12959",
   "metadata": {},
   "source": [
    "### For you to play, apply the classifier on the cancer tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc831a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### LOAD cancer tweets #################\n",
    "import pandas as pd\n",
    "tweets_cancer = pd.read_excel(\"data/cancer_tweets_personal.csv\")\n",
    "print(tweets_cancer.shape)\n",
    "tweets_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98c0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd0f616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e7d83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f345a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61f0b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607c252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
